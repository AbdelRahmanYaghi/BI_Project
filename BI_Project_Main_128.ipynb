{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob2 as glob\n",
    "import pandas as pd\n",
    "import copy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('128_model_weights_3_layers/*.npy')\n",
    "\n",
    "weights_dict = {'bias' : {}, 'weight' : {}}\n",
    "\n",
    "for file in files:\n",
    "    layer_name = file.split('/')[-1].split('.')[0]\n",
    "    if layer_name.split('_')[-1] == 'bias':\n",
    "        weights_dict['bias'].update({layer_name.split('_')[0]: np.load(file)})\n",
    "    else:\n",
    "        weights_dict['weight'].update({layer_name.split('_')[0]: np.load(file)})\n",
    "\n",
    "test_df = pd.read_csv('mnist_test.csv')\n",
    "order= ['fc1', 'fc2', 'fc3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Number\t|\t Weights Shape\t|\t Bias Shape\n",
      "------------------------------------------------------------\n",
      "Layer 1  \t|\t (128, 784) \t|\t (128,)\n",
      "Layer 2  \t|\t (128, 128) \t|\t (128,)\n",
      "Layer 3  \t|\t (10, 128) \t|\t (10,)\n"
     ]
    }
   ],
   "source": [
    "def choose_neurons_numeric(chosen_neurons, _weights_dict):\n",
    "    \n",
    "    weights_dict_ = copy.deepcopy(_weights_dict)\n",
    "        \n",
    "    weights_dict_['weight']['fc1'] = weights_dict_['weight']['fc1'][chosen_neurons[0], :]\n",
    "    weights_dict_['bias']['fc1'] = weights_dict_['bias']['fc1'][chosen_neurons[0]]\n",
    "\n",
    "    weights_dict_['weight']['fc2'] = weights_dict_['weight']['fc2'][chosen_neurons[1], :][:, chosen_neurons[0]]\n",
    "    weights_dict_['bias']['fc2'] = weights_dict_['bias']['fc2'][chosen_neurons[1]]\n",
    "\n",
    "    weights_dict_['weight']['fc3'] = weights_dict_['weight']['fc3'][: ,chosen_neurons[1]]\n",
    "    \n",
    "    return weights_dict_\n",
    "\n",
    "\n",
    "def choose_neurons_slicing(chosen_neurons, _weights_dict):\n",
    "    weights_dict_ = copy.deepcopy(_weights_dict)\n",
    "\n",
    "    #############\n",
    "    ## LAYER 1 ##\n",
    "    #############\n",
    "\n",
    "    # Adding expression to the weights of Layer 1\n",
    "    print('Adding expression to the weights of Layer 1')\n",
    "    new_fc = []\n",
    "    for i in tqdm(range(weights_dict_['weight']['fc1'].shape[0])):\n",
    "        new_fc_row = []\n",
    "        for j in range(weights_dict_['weight']['fc1'].shape[1]):\n",
    "            new_fc_row.append(chosen_neurons[0][i] * weights_dict_['weight']['fc1'][i][j])\n",
    "        new_fc.append(new_fc_row)\n",
    "\n",
    "    weights_dict_['weight']['fc1'] = np.array(new_fc)\n",
    "\n",
    "    # Adding expression to the Bias of Layer 1\n",
    "    print('Adding expression to the bias of Layer 1')\n",
    "    new_fc = []\n",
    "    for i in tqdm(range(weights_dict_['bias']['fc1'].shape[0])):\n",
    "        new_fc.append(chosen_neurons[0][i] * weights_dict_['bias']['fc1'][i])\n",
    "    \n",
    "    weights_dict_['bias']['fc1'] = np.array(new_fc)\n",
    "\n",
    "\n",
    "    #############\n",
    "    ## LAYER 2 ##\n",
    "    #############\n",
    "\n",
    "    # Adding expression to the weights of Layer 2\n",
    "    print('Adding expression to the weights of Layer 2')\n",
    "    \n",
    "    new_fc = weights_dict_['weight']['fc2'].copy().astype(object)\n",
    "    for i in tqdm(range(weights_dict_['weight']['fc2'].shape[0])):\n",
    "        for j in range(weights_dict_['weight']['fc2'].shape[1]):\n",
    "            new_fc[i][j] *= (chosen_neurons[1][i] * chosen_neurons[0][j])\n",
    "\n",
    "    weights_dict_['weight']['fc2'] = new_fc\n",
    "\n",
    "    # Adding expression to the Bias of Layer 2\n",
    "    print('Adding expression to the bias of Layer 2')\n",
    "    new_fc = []\n",
    "    for i in tqdm(range(weights_dict_['bias']['fc2'].shape[0])):\n",
    "        new_fc.append(chosen_neurons[1][i] * weights_dict_['bias']['fc2'][i])\n",
    "    \n",
    "    weights_dict_['bias']['fc2'] = np.array(new_fc)\n",
    "\n",
    "    #############\n",
    "    ## LAYER 3 ##\n",
    "    #############\n",
    "    \n",
    "    # Adding expression to the weights of Layer 3\n",
    "    print('Adding expression to the weights of Layer 3')\n",
    "    \n",
    "    new_fc = weights_dict_['weight']['fc3'].copy().astype(object)\n",
    "    for i in tqdm(range(weights_dict_['weight']['fc3'].shape[0])):\n",
    "        for j in range(weights_dict_['weight']['fc3'].shape[1]):\n",
    "            new_fc[i][j] *= chosen_neurons[1][j]\n",
    "\n",
    "    weights_dict_['weight']['fc3'] = new_fc\n",
    "\n",
    "    return weights_dict_\n",
    "\n",
    "def predict_expressions(expression_matrix, weights_dict_):\n",
    "\n",
    "    x = np.dot(weights_dict_['weight']['fc1'], expression_matrix.T) + weights_dict_['bias']['fc1']\n",
    "    # x = np.maximum(0, x)\n",
    "\n",
    "    print(x)\n",
    "    \n",
    "    for i in x:\n",
    "        print(i)\n",
    "\n",
    "    print(x.shape)\n",
    "\n",
    "    print('Done 1 layer')\n",
    "\n",
    "    x = np.dot(weights_dict_['weight']['fc2'], x.T) + weights_dict_['bias']['fc2']\n",
    "    # x = np.maximum(0, x)\n",
    "\n",
    "\n",
    "    print('Done 2 layer')\n",
    "\n",
    "    x = np.dot(weights_dict_['weight']['fc3'], x.T) + weights_dict_['bias']['fc3']\n",
    "    # x = np.maximum(0, x)\n",
    "\n",
    "    print('Done 3 layer')\n",
    "\n",
    "    x /= np.sum(x) # softmax\n",
    "\n",
    "    return x\n",
    "\n",
    "def predict_numeric(img_df_row, weights_dict_):\n",
    "\n",
    "    x = np.dot(weights_dict_['weight']['fc1'], img_df_row.T) + weights_dict_['bias']['fc1']\n",
    "    x = np.maximum(0, x)\n",
    "\n",
    "    x = np.dot(weights_dict_['weight']['fc2'], x.T) + weights_dict_['bias']['fc2']\n",
    "    x = np.maximum(0, x)\n",
    "\n",
    "    x = np.dot(weights_dict_['weight']['fc3'], x.T) + weights_dict_['bias']['fc3']\n",
    "    x = np.maximum(0, x)\n",
    "\n",
    "    x /= np.sum(x) # softmax\n",
    "\n",
    "    return x\n",
    "\n",
    "def print_neurons_shape(weights_dict_):\n",
    "    print('Layer Number\\t|\\t Weights Shape\\t|\\t Bias Shape')\n",
    "    print('-'*60)\n",
    "    print('Layer 1  \\t|\\t', weights_dict_['weight']['fc1'].shape, '\\t|\\t' , weights_dict_['bias']['fc1'].shape)\n",
    "    print('Layer 2  \\t|\\t', weights_dict_['weight']['fc2'].shape, '\\t|\\t' , weights_dict_['bias']['fc2'].shape)\n",
    "    print('Layer 3  \\t|\\t', weights_dict_['weight']['fc3'].shape, '\\t|\\t' , weights_dict_['bias']['fc3'].shape)\n",
    "    \n",
    "def cross_entropy_loss(label, y_hat):\n",
    "    y = np.zeros(10)\n",
    "    y[label] = 1\n",
    "    return -np.sum(y * np.log(y_hat))\n",
    "\n",
    "print_neurons_shape(weights_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### VALIDATION DRAFT: DO NOT REMOVE AND DO NOT RUN!!! ###\n",
    "\n",
    "# # chosen_fc1 = np.random.randint(0, 2, 2048)\n",
    "# # chosen_fc2 = np.random.randint(0, 2, 2048)\n",
    "\n",
    "# # print(chosen_fc1.sum(), chosen_fc2.sum())\n",
    "\n",
    "# # expressioned_weights = choose_neurons_expression([chosen_fc1, chosen_fc2], weights_dict)\n",
    "\n",
    "# # 1012 1032\n",
    "\n",
    "# print((expressioned_weights['weight']['fc1'].sum(axis = 0) != 0).sum() , (expressioned_weights['weight']['fc1'].sum(axis = 1) != 0).sum())\n",
    "# print((expressioned_weights['weight']['fc2'].sum(axis = 0) != 0).sum() , (expressioned_weights['weight']['fc2'].sum(axis = 1) != 0).sum())\n",
    "# print((expressioned_weights['weight']['fc3'].sum(axis = 0) != 0).sum() , (expressioned_weights['weight']['fc3'].sum(axis = 1) != 0).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DoCplex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docplex.cp.model import CpoModel as Model\n",
    "\n",
    "m = Model()\n",
    "\n",
    "X_fc1 = np.array(m.binary_var_list(128, name='Layer 1 Neurons'))\n",
    "X_fc2 = np.array(m.binary_var_list(128, name='Layer 2 Neurons'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_hat_fc1_weight = X_fc1.reshape((-1, 1))  * weights_dict['weight']['fc1']\n",
    "W_hat_fc1_bias = weights_dict['bias']['fc1'] * X_fc1\n",
    "\n",
    "W_hat_fc2_weight = X_fc2.reshape((-1, 1)) * weights_dict['weight']['fc2']\n",
    "W_hat_fc2_weight = W_hat_fc2_weight * X_fc1.reshape((1, -1))\n",
    "W_hat_fc2_bias = X_fc2 * weights_dict['bias']['fc2']\n",
    "\n",
    "W_hat_fc3_weight = weights_dict['weight']['fc3'] * X_fc2.reshape((1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_chunk = 10\n",
    "data = test_df.drop(columns=['label']).iloc[:sub_chunk]\n",
    "true_class = test_df.iloc[:sub_chunk]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 128)\n",
      "(10, 128)\n",
      "(10, 10)\n"
     ]
    }
   ],
   "source": [
    "out_x = np.dot(data, W_hat_fc1_weight.T) + W_hat_fc1_bias\n",
    "print(out_x.shape)\n",
    "out_x = np.dot(out_x, W_hat_fc2_weight) + W_hat_fc2_bias\n",
    "print(out_x.shape)\n",
    "out_x = np.dot(out_x, W_hat_fc3_weight.T) + weights_dict['bias']['fc3']\n",
    "print(out_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Find index of max for each item in the batch\n",
    "maxs_ = [m.binary_var_list(sub_chunk, name='Largest Index in item {i}') for i in range(len(out_x))]\n",
    "for i in range(sub_chunk):\n",
    "    m.add_constraint(m.sum(maxs_[i][o] for o in range(10)) == 1)\n",
    "    for u in range(10):\n",
    "        m.add_constraint(out_x[i][u] >= m.sum(out_x[i][j] - 10e6*(1-maxs_[i][u]) for j in range(10)))\n",
    "\n",
    "\n",
    "max_of_each_input = []\n",
    "for i in range(sub_chunk):\n",
    "    max_of_each_input.append(m.sum(maxs_[i][j] * out_x[i][j] for j in range(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Apply softmax on the max of each input\n",
    "\n",
    "softmax_of_each_input = []\n",
    "for i in range(sub_chunk):\n",
    "    softmax_of_each_input.append(np.e ** max_of_each_input[i] / m.sum(np.e ** out_x[i][j] for j in range(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate Loss for each input\n",
    "\n",
    "summation_of_loss = []\n",
    "\n",
    "for i in range(sub_chunk):\n",
    "    summation_of_loss.append(-1 * m.log(softmax_of_each_input[i]) *  true_class[i])\n",
    "\n",
    "summation_of_loss = m.sum(summation_of_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<docplex.cp.expression.CpoFunctionCall at 0x79436cc24200>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_nuerons_used = X_fc1.sum() + X_fc2.sum()\n",
    "\n",
    "m.minimize(number_of_nuerons_used + summation_of_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[162], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/GithubRepos/BI_Project/venv/lib/python3.10/site-packages/docplex/cp/model.py:1289\u001b[0m, in \u001b[0;36mCpoModel.solve\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1246\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" Solves the model.\u001b[39;00m\n\u001b[1;32m   1247\u001b[0m \n\u001b[1;32m   1248\u001b[0m \u001b[38;5;124;03mThis method solves the model using the appropriate :class:`~docplex.cp.solver.solver.CpoSolver`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1286\u001b[0m \u001b[38;5;124;03m    :class:`~docplex.cp.utils.CpoException`: (or derived) if error.\u001b[39;00m\n\u001b[1;32m   1287\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1288\u001b[0m solver \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_solver(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1289\u001b[0m msol \u001b[38;5;241m=\u001b[39m \u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1290\u001b[0m solver\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m   1291\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m msol\n",
      "File \u001b[0;32m~/GithubRepos/BI_Project/venv/lib/python3.10/site-packages/docplex/cp/solver/solver.py:707\u001b[0m, in \u001b[0;36mCpoSolver.solve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    705\u001b[0m stime \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 707\u001b[0m     msol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    709\u001b[0m     \u001b[38;5;66;03m# Check if aborted in the mean time\u001b[39;00m\n\u001b[1;32m    710\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_status_aborted():\n",
      "File \u001b[0;32m~/GithubRepos/BI_Project/venv/lib/python3.10/site-packages/docplex/cp/solver/solver_local.py:213\u001b[0m, in \u001b[0;36mCpoSolverLocal.solve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write_message(CMD_SOLVE_MODEL)\n\u001b[1;32m    212\u001b[0m \u001b[38;5;66;03m# Wait JSON result\u001b[39;00m\n\u001b[0;32m--> 213\u001b[0m jsol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_json_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEVT_SOLVE_RESULT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;66;03m# Build result object\u001b[39;00m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_result_object(CpoSolveResult, jsol)\n",
      "File \u001b[0;32m~/GithubRepos/BI_Project/venv/lib/python3.10/site-packages/docplex/cp/solver/solver_local.py:572\u001b[0m, in \u001b[0;36mCpoSolverLocal._wait_json_result\u001b[0;34m(self, evt)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" Wait for a JSON result while forwarding logs if any.\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;124;03m    evt: Event to wait for\u001b[39;00m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;124;03mReturns:\u001b[39;00m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;124;03m    JSON solution string, decoded from UTF8\u001b[39;00m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;66;03m# Wait JSON result\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;66;03m# Store last json result\u001b[39;00m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_last_json_result_string(data)\n",
      "File \u001b[0;32m~/GithubRepos/BI_Project/venv/lib/python3.10/site-packages/docplex/cp/solver/solver_local.py:467\u001b[0m, in \u001b[0;36mCpoSolverLocal._wait_event\u001b[0;34m(self, xevt)\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;66;03m# Read events\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;66;03m# Read and process next message\u001b[39;00m\n\u001b[0;32m--> 467\u001b[0m     evt, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m evt \u001b[38;5;241m==\u001b[39m xevt:\n\u001b[1;32m    470\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/GithubRepos/BI_Project/venv/lib/python3.10/site-packages/docplex/cp/solver/solver_local.py:631\u001b[0m, in \u001b[0;36mCpoSolverLocal._read_message\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" Read a message from the solver process\u001b[39;00m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;124;03mReturns:\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;124;03m    Tuple (evt, data)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;66;03m# Read message header\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m frame \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (frame[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0xCA\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (frame[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0xFE\u001b[39m):\n\u001b[1;32m    633\u001b[0m     erline \u001b[38;5;241m=\u001b[39m frame \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_error_message()\n",
      "File \u001b[0;32m~/GithubRepos/BI_Project/venv/lib/python3.10/site-packages/docplex/cp/solver/solver_local.py:676\u001b[0m, in \u001b[0;36mCpoSolverLocal._read_frame\u001b[0;34m(self, nbb)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" Read a byte frame from input stream\u001b[39;00m\n\u001b[1;32m    670\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;124;03m    nbb:  Number of bytes to read\u001b[39;00m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;124;03mReturns:\u001b[39;00m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;124;03m    Byte array\u001b[39;00m\n\u001b[1;32m    674\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;66;03m# Read data\u001b[39;00m\n\u001b[0;32m--> 676\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m nbb:\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    679\u001b[0m         \u001b[38;5;66;03m# Check if first read of data\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "m.solve(log_output=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob2 as glob\n",
    "import pandas as pd\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('16_8_model_weights_3_layers/*.npy')\n",
    "\n",
    "weights_dict = {'bias' : {}, 'weight' : {}}\n",
    "\n",
    "for file in files:\n",
    "    layer_name = file.split('/')[-1].split('.')[0]\n",
    "    if layer_name.split('_')[-1] == 'bias':\n",
    "        weights_dict['bias'].update({layer_name.split('_')[0]: np.load(file)})\n",
    "    else:\n",
    "        weights_dict['weight'].update({layer_name.split('_')[0]: np.load(file)})\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "test_df = pd.read_csv('Iris.csv').drop(columns = ['Id'])\n",
    "test_df['Species'] = test_df['Species'].map({'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica': 2})\n",
    "\n",
    "test_y = test_df['Species']\n",
    "test_x = test_df.drop(columns = ['Species'])\n",
    "test_x = pd.DataFrame(scaler.fit_transform(test_x), columns = test_x.columns)\n",
    "\n",
    "order= ['fc1', 'fc2', 'fc3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Number\t|\t Weights Shape\t|\t Bias Shape\n",
      "------------------------------------------------------------\n",
      "Layer 1  \t|\t (16, 4) \t|\t (16,)\n",
      "Layer 2  \t|\t (8, 16) \t|\t (8,)\n",
      "Layer 3  \t|\t (3, 8) \t|\t (3,)\n"
     ]
    }
   ],
   "source": [
    "def choose_neurons_numeric(chosen_neurons, _weights_dict):\n",
    "    \n",
    "    weights_dict_ = copy.deepcopy(_weights_dict)\n",
    "        \n",
    "    weights_dict_['weight']['fc1'] = weights_dict_['weight']['fc1'][chosen_neurons[0], :]\n",
    "    weights_dict_['bias']['fc1'] = weights_dict_['bias']['fc1'][chosen_neurons[0]]\n",
    "\n",
    "    weights_dict_['weight']['fc2'] = weights_dict_['weight']['fc2'][chosen_neurons[1], :][:, chosen_neurons[0]]\n",
    "    weights_dict_['bias']['fc2'] = weights_dict_['bias']['fc2'][chosen_neurons[1]]\n",
    "\n",
    "    weights_dict_['weight']['fc3'] = weights_dict_['weight']['fc3'][: ,chosen_neurons[1]]\n",
    "    \n",
    "    return weights_dict_\n",
    "\n",
    "def choose_neurons_matmul(chosen_neurons, _weights_dict):\n",
    "    weights_dict_ = copy.deepcopy(_weights_dict)\n",
    "\n",
    "    weights_dict_['weight']['fc1'] = chosen_neurons[0] * weights_dict_['weight']['fc1']\n",
    "\n",
    "    weights_dict_['weight']['fc2'] = chosen_neurons[1] * weights_dict_['weight']['fc2']\n",
    "    weights_dict_['weight']['fc2'] = weights_dict_['weight']['fc2'] * chosen_neurons[0].T\n",
    "\n",
    "    weights_dict_['weight']['fc3'] = weights_dict_['weight']['fc3'] * chosen_neurons[1].T\n",
    "\n",
    "    weights_dict_['bias']['fc1'] = chosen_neurons[0].flatten() * weights_dict_['bias']['fc1'].flatten()\n",
    "    weights_dict_['bias']['fc2'] = chosen_neurons[1].flatten() * weights_dict_['bias']['fc2'].flatten()\n",
    "\n",
    "    return weights_dict_\n",
    "\n",
    "def predict_numeric(img_df_row, weights_dict_):\n",
    "\n",
    "    x = np.dot(weights_dict_['weight']['fc1'], img_df_row.T) + weights_dict_['bias']['fc1']\n",
    "\n",
    "    x = np.dot(weights_dict_['weight']['fc2'], x) + weights_dict_['bias']['fc2']\n",
    "\n",
    "    x = np.dot(weights_dict_['weight']['fc3'], x) + weights_dict_['bias']['fc3']\n",
    "\n",
    "    return x\n",
    "\n",
    "def print_neurons_shape(weights_dict_):\n",
    "    print('Layer Number\\t|\\t Weights Shape\\t|\\t Bias Shape')\n",
    "    print('-'*60)\n",
    "    print('Layer 1  \\t|\\t', weights_dict_['weight']['fc1'].shape, '\\t|\\t' , weights_dict_['bias']['fc1'].shape)\n",
    "    print('Layer 2  \\t|\\t', weights_dict_['weight']['fc2'].shape, '\\t|\\t' , weights_dict_['bias']['fc2'].shape)\n",
    "    print('Layer 3  \\t|\\t', weights_dict_['weight']['fc3'].shape, '\\t|\\t' , weights_dict_['bias']['fc3'].shape)\n",
    "    \n",
    "def cross_entropy_loss(label, y_hat):\n",
    "    y = np.zeros(10)\n",
    "    y[label] = 1\n",
    "    return -np.sum(y * np.log(y_hat))\n",
    "\n",
    "print_neurons_shape(weights_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9733333333333334\n",
      "0.06532579124930898\n"
     ]
    }
   ],
   "source": [
    "### Validation of results\n",
    "\n",
    "my_test_weights = choose_neurons_numeric([list(range(16)), list(range(8))], weights_dict)\n",
    "\n",
    "preds = np.array([predict_numeric(i, my_test_weights) for i in test_x.values])\n",
    "\n",
    "counter = 0\n",
    "for i in range(len(preds)):\n",
    "    if preds[i].argmax() == test_y.iloc[i]:\n",
    "        counter += 1\n",
    "\n",
    "print(counter/150)\n",
    "\n",
    "\n",
    "def cross_entropy_loss(label, y_hat):\n",
    "\n",
    "    y = np.zeros_like(y_hat)\n",
    "    y[np.arange(label.shape[0]), label] = 1 \n",
    "\n",
    "    exp_preds = np.exp(y_hat)\n",
    "\n",
    "    softmaxed_preds = exp_preds / exp_preds.sum(axis=1, keepdims=True)\n",
    "\n",
    "    return -np.sum(y * np.log(softmaxed_preds)) / len(test_y)\n",
    "\n",
    "print(cross_entropy_loss(test_y, preds)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DoCplex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<docplex.cp.expression.CpoFunctionCall at 0x7397b5cc2fc0>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from docplex.cp.model import CpoModel as Model\n",
    "\n",
    "m = Model()\n",
    "\n",
    "X_fc1 = np.array(m.binary_var_list(16, name='Layer 1 Neurons')).reshape((-1, 1))\n",
    "X_fc2 = np.array(m.binary_var_list(8, name='Layer 2 Neurons')).reshape((-1, 1))\n",
    "\n",
    "new_weights_dict = choose_neurons_matmul([X_fc1, X_fc2], weights_dict)\n",
    "\n",
    "accuracy = 0\n",
    "\n",
    "preds = np.array([predict_numeric(i, my_test_weights) for i in test_x.values])\n",
    "\n",
    "loss = cross_entropy_loss(test_y, preds)\n",
    "    \n",
    "neurons_used = np.sum(X_fc1) + np.sum(X_fc2) \n",
    "\n",
    "m.minimize(loss + (neurons_used*alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ! --------------------------------------------------- CP Optimizer 22.1.1.0 --\n",
      " ! Minimization problem - 24 variables, 0 constraints\n",
      " ! Presolve      : 2 extractables eliminated\n",
      " ! Initial process time : 0.00s (0.00s extraction + 0.00s propagation)\n",
      " !  . Log search space  : 24.0 (before), 24.0 (after)\n",
      " !  . Memory usage      : 300.5 kB (before), 300.5 kB (after)\n",
      " ! Using parallel search with 4 workers.\n",
      " ! ----------------------------------------------------------------------------\n",
      " !          Best Branches  Non-fixed    W       Branch decision\n",
      "                        0         24                 -\n",
      " + New bound is 0.06532579\n",
      "      0.06532579        0         24    1            -\n",
      " *    0.06532579        0  0.02s        1      (gap is 0.00%)\n",
      " ! ----------------------------------------------------------------------------\n",
      " ! Search completed, 1 solution found.\n",
      " ! Best objective         : 0.06532579 (optimal - effective tol. is 6.532579e-06)\n",
      " ! Best bound             : 0.06532579\n",
      " ! ----------------------------------------------------------------------------\n",
      " ! Number of branches     : 40\n",
      " ! Number of fails        : 23\n",
      " ! Total memory usage     : 2.4 MB (2.3 MB CP Optimizer + 0.0 MB Concert)\n",
      " ! Time spent in solve    : 0.02s (0.02s engine + 0.00s extraction)\n",
      " ! Search speed (br. / s) : 4000.0\n",
      " ! ----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# stp = m.create_empty_solution()\n",
    "# stp[X_fc1] = [1 for i in X_fc1]\n",
    "# stp[X_fc2] = [1 for i in X_fc2]\n",
    "# m.set_starting_point(stp)\n",
    "\n",
    "sol = m.solve(log_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(sol.get_all_var_solutions()[i]) for i in range(len(sol.get_all_var_solutions()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1223.971001051563\n"
     ]
    }
   ],
   "source": [
    "print(sol.get_objective_value())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hPqxr2G8dT6-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import glob2 as glob\n",
        "import pandas as pd\n",
        "import copy\n",
        "from tqdm import tqdm\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qIn-8DTndT7B"
      },
      "outputs": [],
      "source": [
        "files = glob.glob('16_8_model_weights_3_layers/*.npy')\n",
        "\n",
        "weights_dict = {'bias' : {}, 'weight' : {}}\n",
        "\n",
        "for file in files:\n",
        "    layer_name = file.split('/')[-1].split('.')[0]\n",
        "    if layer_name.split('_')[-1] == 'bias':\n",
        "        weights_dict['bias'].update({layer_name.split('_')[0]: np.load(file)})\n",
        "    else:\n",
        "        weights_dict['weight'].update({layer_name.split('_')[0]: np.load(file)})\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "\n",
        "test_df = pd.read_csv('Iris.csv').drop(columns = ['Id'])\n",
        "test_df['Species'] = test_df['Species'].map({'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica': 2})\n",
        "\n",
        "test_y = test_df['Species']\n",
        "test_x = test_df.drop(columns = ['Species'])\n",
        "test_x = pd.DataFrame(scaler.fit_transform(test_x), columns = test_x.columns)\n",
        "\n",
        "order= ['fc1', 'fc2', 'fc3']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "75k0BU0ZdT7C",
        "outputId": "2e533f08-c3f2-494c-ddc0-947816d44b16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layer Number\t|\t Weights Shape\t|\t Bias Shape\n",
            "------------------------------------------------------------\n",
            "Layer 1  \t|\t (16, 4) \t|\t (16,)\n",
            "Layer 2  \t|\t (8, 16) \t|\t (8,)\n",
            "Layer 3  \t|\t (3, 8) \t|\t (3,)\n"
          ]
        }
      ],
      "source": [
        "def choose_neurons_numeric(chosen_neurons, _weights_dict):\n",
        "\n",
        "    weights_dict_ = copy.deepcopy(_weights_dict)\n",
        "\n",
        "    weights_dict_['weight']['fc1'] = weights_dict_['weight']['fc1'][chosen_neurons[0], :]\n",
        "    weights_dict_['bias']['fc1'] = weights_dict_['bias']['fc1'][chosen_neurons[0]]\n",
        "\n",
        "    weights_dict_['weight']['fc2'] = weights_dict_['weight']['fc2'][chosen_neurons[1], :][:, chosen_neurons[0]]\n",
        "    weights_dict_['bias']['fc2'] = weights_dict_['bias']['fc2'][chosen_neurons[1]]\n",
        "\n",
        "    weights_dict_['weight']['fc3'] = weights_dict_['weight']['fc3'][: ,chosen_neurons[1]]\n",
        "\n",
        "    return weights_dict_\n",
        "\n",
        "def choose_neurons_matmul(chosen_neurons, _weights_dict):\n",
        "    weights_dict_ = copy.deepcopy(_weights_dict)\n",
        "\n",
        "    weights_dict_['weight']['fc1'] = chosen_neurons[0] * weights_dict_['weight']['fc1']\n",
        "\n",
        "    weights_dict_['weight']['fc2'] = chosen_neurons[1] * weights_dict_['weight']['fc2']\n",
        "    weights_dict_['weight']['fc2'] = weights_dict_['weight']['fc2'] * chosen_neurons[0].T\n",
        "\n",
        "    weights_dict_['weight']['fc3'] = weights_dict_['weight']['fc3'] * chosen_neurons[1].T\n",
        "\n",
        "    weights_dict_['bias']['fc1'] = chosen_neurons[0].flatten() * weights_dict_['bias']['fc1'].flatten()\n",
        "    weights_dict_['bias']['fc2'] = chosen_neurons[1].flatten() * weights_dict_['bias']['fc2'].flatten()\n",
        "\n",
        "    return weights_dict_\n",
        "\n",
        "def predict_numeric(img_df_row, weights_dict_):\n",
        "\n",
        "    x = np.dot(weights_dict_['weight']['fc1'], img_df_row.T) + weights_dict_['bias']['fc1']\n",
        "\n",
        "    x = np.dot(weights_dict_['weight']['fc2'], x) + weights_dict_['bias']['fc2']\n",
        "\n",
        "    x = np.dot(weights_dict_['weight']['fc3'], x) + weights_dict_['bias']['fc3']\n",
        "\n",
        "    return x\n",
        "\n",
        "def print_neurons_shape(weights_dict_):\n",
        "    print('Layer Number\\t|\\t Weights Shape\\t|\\t Bias Shape')\n",
        "    print('-'*60)\n",
        "    print('Layer 1  \\t|\\t', weights_dict_['weight']['fc1'].shape, '\\t|\\t' , weights_dict_['bias']['fc1'].shape)\n",
        "    print('Layer 2  \\t|\\t', weights_dict_['weight']['fc2'].shape, '\\t|\\t' , weights_dict_['bias']['fc2'].shape)\n",
        "    print('Layer 3  \\t|\\t', weights_dict_['weight']['fc3'].shape, '\\t|\\t' , weights_dict_['bias']['fc3'].shape)\n",
        "\n",
        "print_neurons_shape(weights_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "teWfFI8cdT7E",
        "outputId": "882716c4-56de-4c15-d5d4-2800a68a0082"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9733333333333334\n",
            "0.06532579124930898\n"
          ]
        }
      ],
      "source": [
        "### Validation of results\n",
        "\n",
        "my_test_weights = choose_neurons_numeric([list(range(16)), list(range(8))], weights_dict)\n",
        "\n",
        "preds = np.array([predict_numeric(i, my_test_weights) for i in test_x.values])\n",
        "\n",
        "counter = 0\n",
        "for i in range(len(preds)):\n",
        "    if preds[i].argmax() == test_y.iloc[i]:\n",
        "        counter += 1\n",
        "\n",
        "print(counter/150)\n",
        "\n",
        "def cross_entropy_loss(label, y_hat):\n",
        "\n",
        "    y = np.zeros_like(y_hat)\n",
        "    y[np.arange(label.shape[0]), label] = 1\n",
        "\n",
        "    exp_preds = np.exp(y_hat)\n",
        "\n",
        "    softmaxed_preds = exp_preds / exp_preds.sum(axis=1, keepdims=True)\n",
        "\n",
        "    return -np.sum(y * np.log(softmaxed_preds)) / len(test_y)\n",
        "\n",
        "\n",
        "def cross_entropy_loss_cplex(label, y_hat, model):\n",
        "\n",
        "    y = np.zeros_like(y_hat)\n",
        "    y[np.arange(label.shape[0]), label] = 1\n",
        "\n",
        "    exp_preds = np.e**(y_hat)\n",
        "\n",
        "    softmaxed_preds = exp_preds / exp_preds.sum(axis=1, keepdims=True)\n",
        "\n",
        "    to_sum = []\n",
        "\n",
        "    for u, i in zip(y, softmaxed_preds):\n",
        "      for o, j in zip(u, i):\n",
        "        to_sum.append(o * m.log(j))\n",
        "\n",
        "\n",
        "    return -np.sum(to_sum) / len(test_y)\n",
        "\n",
        "\n",
        "print(cross_entropy_loss(test_y, preds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApmryvAAdT7G"
      },
      "source": [
        "### DoCplex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "D_YshTxwdod-"
      },
      "outputs": [],
      "source": [
        "# %%capture\n",
        "# !pip install docplex cplex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edFSYVUJdT7G",
        "outputId": "3646f385-a5e2-478b-cbd2-d1647903665b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<docplex.cp.expression.CpoFunctionCall at 0x7990c8fbe640>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from docplex.cp.model import CpoModel as Model\n",
        "\n",
        "m = Model()\n",
        "\n",
        "X_fc1 = np.array(m.binary_var_list(16, name='Layer 1 Neurons')).reshape((-1, 1))\n",
        "X_fc2 = np.array(m.binary_var_list(8, name='Layer 2 Neurons')).reshape((-1, 1))\n",
        "\n",
        "neurons_used = np.sum(X_fc1) + np.sum(X_fc2)\n",
        "\n",
        "### 16 takes way too much time\n",
        "m.add_constraint(neurons_used == 22)\n",
        "\n",
        "new_weights_dict = choose_neurons_matmul([X_fc1, X_fc2], weights_dict)\n",
        "\n",
        "preds = np.array([predict_numeric(i, new_weights_dict) for i in test_x.values])\n",
        "\n",
        "loss = cross_entropy_loss_cplex(test_y, preds, m)\n",
        "\n",
        "m.minimize(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5Hlc-h4dT7H",
        "outputId": "143012a4-687a-45b1-fad2-7a22e6c867e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ! --------------------------------------------------- CP Optimizer 22.1.1.0 --\n",
            " ! Minimization problem - 24 variables, 1 constraint\n",
            " ! Presolve      : 2 extractables eliminated\n",
            " ! Initial process time : 0.33s (0.33s extraction + 0.01s propagation)\n",
            " !  . Log search space  : 24.0 (before), 24.0 (after)\n",
            " !  . Memory usage      : 13.1 MB (before), 13.1 MB (after)\n",
            " ! Using parallel search with 4 workers.\n",
            " ! ----------------------------------------------------------------------------\n",
            " !          Best Branches  Non-fixed    W       Branch decision\n",
            "                        0         24                 -\n",
            " + New bound is -13.68917\n",
            "                        0         24    1   F        -\n",
            " + New bound is -13.30776\n",
            " *     0.1844661        2  21.58s       1      (gap is 7314%)\n",
            " *    0.09995524        4  21.58s       1      (gap  > 10000%)\n",
            " *    0.07696352       19  21.58s       1      (gap  > 10000%)\n",
            " *    0.07601327       21  21.58s       1      (gap  > 10000%)\n",
            " *    0.07283534       48  21.58s       1      (gap  > 10000%)\n",
            " *    0.07042406      166  21.58s       1      (gap  > 10000%)\n",
            " *    0.06966609      220  21.58s       1      (gap  > 10000%)\n",
            " *    0.06843253      338  21.58s       1      (gap  > 10000%)\n",
            " *    0.06834194      436  21.58s       1      (gap  > 10000%)\n",
            "      0.06834194     1000          2    1   F     0  = Layer 1 Neurons_12\n",
            " *    0.06834194      713  21.58s       2      (gap  > 10000%)\n",
            "      0.06834194     1000          2    2   F     1 != Layer 1 Neurons_3\n",
            " *    0.06834194      282  21.59s       3      (gap  > 10000%)\n",
            "      0.06834194     1000          2    3   F     0  = Layer 2 Neurons_5\n",
            "      0.06834194      957          2    4            -\n",
            " + New bound is 0.06833511 (gap is 0.01%)\n",
            " ! ----------------------------------------------------------------------------\n",
            " ! Search completed, 11 solutions found.\n",
            " ! Best objective         : 0.06834194 (optimal - effective tol. is 6.834195e-06)\n",
            " ! Best bound             : 0.06833511\n",
            " ! ----------------------------------------------------------------------------\n",
            " ! Number of branches     : 3960\n",
            " ! Number of fails        : 1892\n",
            " ! Total memory usage     : 124.1 MB (124.0 MB CP Optimizer + 0.0 MB Concert)\n",
            " ! Time spent in solve    : 21.60s (21.28s engine + 0.33s extraction)\n",
            " ! Search speed (br. / s) : 186.1\n",
            " ! ----------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "sol = m.solve(log_output=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "34TZYxwEdT7J",
        "outputId": "f7cc7540-ec36-46f5-e05d-3dcf2b692e2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 13 15]\n",
            "[0 1 2 3 4 5 6 7]\n"
          ]
        }
      ],
      "source": [
        "layer1 = np.ones(16)\n",
        "layer2 = np.ones(8)\n",
        "\n",
        "for i in sol.get_all_var_solutions():\n",
        "  _, layer_number, neuron_number = i.get_name().split(' ')\n",
        "\n",
        "  neuron_number_int = int(neuron_number.split('_')[-1])\n",
        "\n",
        "  if layer_number == '1':\n",
        "    layer1[neuron_number_int] = (i.get_value())\n",
        "\n",
        "  if layer_number == '2':\n",
        "    layer2[neuron_number_int] = (i.get_value())\n",
        "\n",
        "print(np.where(layer1 == 1)[0])\n",
        "print(np.where(layer2 == 1)[0])\n",
        "\n",
        "new_weights_chosen = choose_neurons_numeric([np.where(layer1 == 1)[0], np.where(layer2 == 1)[0]], weights_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "yS6-7mKfdT7K",
        "outputId": "f3192a5a-1e88-4779-eb43-455e7f60652d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.98\n",
            "0.06834194626070883\n"
          ]
        }
      ],
      "source": [
        "preds = np.array([predict_numeric(i, new_weights_chosen) for i in test_x.values])\n",
        "\n",
        "counter = 0\n",
        "for i in range(len(preds)):\n",
        "    if preds[i].argmax() == test_y.iloc[i]:\n",
        "        counter += 1\n",
        "\n",
        "print(counter/150)\n",
        "\n",
        "def cross_entropy_loss(label, y_hat):\n",
        "\n",
        "    y = np.zeros_like(y_hat)\n",
        "    y[np.arange(label.shape[0]), label] = 1\n",
        "\n",
        "    exp_preds = np.exp(y_hat)\n",
        "\n",
        "    softmaxed_preds = exp_preds / exp_preds.sum(axis=1, keepdims=True)\n",
        "\n",
        "    return -np.sum(y * np.log(softmaxed_preds)) / len(test_y)\n",
        "\n",
        "print(cross_entropy_loss(test_y, preds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "zg8jpnecdT7L",
        "outputId": "72e7ece8-4df6-4e68-83b2-4c38e65b7af1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.06834194626073234"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sol.get_objective_value()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFRmi4QLxjWL"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
